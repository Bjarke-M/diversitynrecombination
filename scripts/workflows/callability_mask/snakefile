#workflow for assessing filtering the GENOME VCF files and generating BED files for each individual, only with the sites that pass the filters.
# Define a Python function to generate the expand statement

# Define the list of species you want to process
species_list = ['Daubentonia_madagascariensis']

input_file = '/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/PDGP_metadata.txt'
dictionary_of_inds = {}
with open(input_file, 'r') as file:
    header = next(file)  # Read and skip the header line
    for line in file:
        fields = line.strip().split(',')
        pdgp_id, genus, species, froh, sex, ref_assembly = fields
        if not ref_assembly:  # Check if ref_assembly is empty
            ref_assembly = 'unknown'
        # Add the pdgp_id to the appropriate category in the dictionary
        if ref_assembly not in dictionary_of_inds:
            dictionary_of_inds[ref_assembly] = [pdgp_id]
        else:
            dictionary_of_inds[ref_assembly].append(pdgp_id)

# Define a Python function to generate the expand statement
def generate_input_paths(species_list, lifted_bed=False):
    input_paths = []
    for species in species_list:
        if lifted_bed:
            input_paths.extend([
                f"/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/beds/{pdgp_id}_bed_lifted.bed"
                for pdgp_id in dictionary_of_inds[species]
            ])
        else:
            input_paths.extend([
                f"/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/{pdgp_id}.bed"
                for pdgp_id in dictionary_of_inds[species]
            ])
    return input_paths


# Modify the rule all to use species_list for both original and lifted BED files
rule all:
    input:
        expand(generate_input_paths(species_list), species=species_list),
        expand(generate_input_paths(species_list, lifted_bed=True), species=species_list)

# Rule to generate individual BED files based on specified criteria
rule generate_ind_beds:
    input:
        vcf="/home/bjarkemp/primatediversity/data/het_data_11_04_2022/{pdgp_id}/{pdgp_id}_concat.vcf.gz",
    output:
        output_file="/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/{pdgp_id}.bed",
        modcov_file="/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/{pdgp_id}_modcov.txt"
    params:
        MIN_HET_AD=3,  # Adjust this value as needed
        GQ=30  # Adjust this value as needed
    shell:
        """
        modcov=$(bcftools stats -d 2,500,1 {input.vcf} | grep 'DP' | \
        grep -iv -e '#' -e '<' -e '>' | sort -k 6 -V -r | head -1 | awk '{{print $3}}')
        echo $modcov > {output.modcov_file}
        min_cov=$((modcov / 2))
        max_cov=$((modcov * 2))
        # Define the output file path for the current individual
        # Apply filters and process variants, output to the defined file path
        bcftools view {input.vcf} | \
            bcftools filter -e "(GT='./.') | (GT='het' & FMT/AD[*:*] < {params.MIN_HET_AD} ) | FMT/DP <= $min_cov | FMT/DP >= $max_cov | FMT/GQ <= {params.GQ}" | \
            grep -v '#' | \
            awk 'BEGIN{{OFS="\\t"}}{{ print $1, $2-1, $2 }}' - | \
            bedtools merge | \
            sort -k1,1 -k2,2n | \
            bedtools merge > {output.output_file}
        """

#lift bed files to the human reference genome
rule liftover_generate_bed:
    input:
        chain_file="/home/bjarkemp/primatediversity/data/chain_files_15_03_2022/{species}_To_hg38.liftOver.gz",
        input_bed= '/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/{pdgp_id}.bed'
    output:
        bed="/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/data/mask/{species}/beds/{pdgp_id}_bed_lifted.bed",
        unmapbed="/home/bjarkemp/primatediversity/people/bjarkemp/diversitynrecombination/mask/{species}/beds/{pdgp_id}_bed_lifted.bed.unmap"
    shell:
        """
        # Run CrossMap.py to perform liftover and generate VCF files
        CrossMap.py bed --chromid l --no-comp-alleles {input.chain_file} {input.input_bed} {output.bed} 
        bedtools sort -i {output.bed} > {output.bed}
        bedtools sort -i {output.unmapbed} > {output.unmapbed}
        """


